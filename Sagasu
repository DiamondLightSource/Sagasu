#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Fri Mar 13 14:48:45 2020
@author: Christian M. Orr
"""

################ SETUP ################

#imports
import os, re
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from sklearn.cluster import DBSCAN
import heapq

plot_kwds = {'alpha' : 0.25, 's' : 80, 'linewidths':0}
os.system("module load mx")
os.system("module load global/cluster")
path = os.getcwd()
print("You are here: "+path)
print("")

print("""
探す探す探す探す探す探す探す探す探す探す探す探す探す探す探
探す .------..------..------..------..------..------. 探す
探す |S.--. ||A.--. ||G.--. ||A.--. ||S.--. ||U.--. | 探す
探す | :/\: || (\/) || :/\: || (\/) || :/\: || (\/) | 探す
探す | :\/: || :\/: || :\/: || :\/: || :\/: || :\/: | 探す
探す | '--'S|| '--'A|| '--'G|| '--'A|| '--'S|| '--'U| 探す
探す `------'`------'`------'`------'`------'`------' 探す
探す探す探す探す探す探す探す探す探す探す探す探す探す探す探
                                      C.ORR 2020


You will need to have run shelxc beforehand. This can be done via hkl2map.

The project name must be exactly the prefix using in hkl2map
eg. for 'proteinA_fa.hkl' use 'proteinA'

The path must be FULL with no / at the end
eg '/dls/here/is/wherethedata/is'

If you only want to run analysis, run from the same place you ran processing but leave the questions on project path and cluster blank.
Make sure all of the other inputs are kept the same.

Results will be printed in this console. Graphs will be saved in ./projectname_results/

      """)

#user inputs
pro_or_ana = (input("Would you like to run processing followed by analysis (p) or just analysis (a)? ")).lower()
print("")
print("***Setup***")
projname = input("Name of project (SHELX prefix): ") 
if pro_or_ana == 'p': 
    fa_path = input("Path to SHELXC outputs: ")
lowres = int((1 + (10 * float(input("Low resolution cutoff for grid: ")))))
l2 = (lowres - 1) / 10
highres = int((10 * float(input("High resolution cutoff for grid: "))))
h2 = highres / 10
lowsites = int(input("Minimum number of sites to search: "))
highsites = int(input("Maximum number of sites to search: "))
if pro_or_ana == 'p':
    clust = (str(input("Run on (c)luster or (l)ocal machine? "))).lower()
if pro_or_ana == 'p':    
    ntry = int(input("Number of trials: "))
else:
    ntry = 1
if pro_or_ana == 'p':    
    hklin = os.path.join(fa_path, projname+"_fa.hkl")
    insin = os.path.join(fa_path, projname+"_fa.ins")
totalrun = (((lowres - 1) - highres)) * (highsites - lowsites)
trytot = (totalrun * ntry)   
clusteranalysis = (str(input("Do you want to run cluster analysis in addition to outlier analysis (time consuming)? (y/n) "))).lower()
if pro_or_ana == 'p':
    print("You have chosen the project name "+projname+" in location "+fa_path)
    print("")
    if clust == 'l':
        print("This will run the grid search on this machine between "+str(l2)+"A and "+str(h2)+"A. The site range is between "+str(lowsites)+" and "+str(highsites)+". As you are running on a local machine, this search may take quite a long time")
    if clust == 'c':       
        print("This will run the grid search on the Diamond cluster between "+str(l2)+"A and "+str(h2)+"A. The site range is between "+str(lowsites)+" and "+str(highsites)+". Please open another terminal to check on the queue status - 'qstat'")
    print("")
    print("Number of shelxd runs: "+str(totalrun))
    print("Grand total number of trys: "+str(trytot))
else:
    print("Running in analysis only mode")
pro = input("Press enter to continue.")

#write shelx job file
shelxjob = open("shelxd_job.sh","w")
shelxjob.write("module load shelx\n")
shelxjob.write("shelxd "+projname+"_fa")
shelxjob.close()
os.chmod('shelxd_job.sh', 0o775)
os.system("rm "+projname+"_results/mad.csv")
    
 # Read contents from file as a single string. Use RE package to allow for replacement
def replace(file, pattern, subst):
    file_handle = open(file, 'r')
    file_string = file_handle.read()
    file_handle.close()
    file_string = (re.sub(pattern, subst, file_string))
    file_handle = open(file, 'w')
    file_handle.write(file_string)
    file_handle.close()

def results(filename):
    with open(filename, 'r') as file:
        filedata = file.read()
        filedata = filedata.replace('/', ' ')
        filedata = filedata.replace(',', ' ')
        filedata = filedata.replace('CC', '')
        filedata = filedata.replace('All', '')
        filedata = filedata.replace('Weak', '')
        filedata = filedata.replace('CFOM', '')
        filedata = filedata.replace('best', '')
        filedata = filedata.replace('PATFOM', '')
        filedata = filedata.replace('CPU', '')
    with open(filename, 'w') as file:
        file.write(filedata)
    with open(filename, 'r') as infile, open(path+"/"+projname+"_results/"+str(i)+"_"+str(j)+".csv", 'w') as outfile:
        for line in infile:
            if line.startswith(" Try"):
                outfile.write(','.join(line.split())+'\n')
    with open(path+"/"+projname+"_results/"+str(i)+"_"+str(j)+".csv", 'r') as f:
        data = f.read()
        with open(path+"/"+projname+"_results/"+str(i)+"_"+str(j)+".csv", 'w') as w:
            w.write(data[:-1])

def analysis(filename, nums):
    df = pd.read_csv(filename, sep=',', names=['linebeg', 'TRY', 'CPUNO', 'CCALL', 'CCWEAK', 'CFOM', 'BEST', 'PATFOM'])
    ccallweak = df[['CCALL', 'CCWEAK']]
    clustr = DBSCAN(eps=0.7, min_samples=1, n_jobs=-1).fit(ccallweak)
    labels = len(set(clustr.labels_))
    print("There are "+str(labels)+" cluster(s)")
    plt.scatter(df['CCALL'], df['CCWEAK'], c= clustr.labels_.astype(float), s=50, alpha=0.5)
    plt.draw()
    ccallvsccweak = plt.gcf()
    ccallvsccweak.savefig(path+"/"+projname+"_figures/"+nums+".png", dpi=150)
    #plt.show()

def outliers(filename, resolution, sitessearched):
    df = pd.read_csv(filename, sep=',', names=['linebeg', 'TRY', 'CPUNO', 'CCALL', 'CCWEAK', 'CFOM', 'BEST', 'PATFOM'])
    pd.DataFrame.drop(df, labels = "linebeg", axis=1, inplace=True)
    median = df['CCALL'].median()
    mad = np.median(np.sqrt((df['CCALL'] - median)**2))
    ccallmax = heapq.nlargest(3, df['CCALL'])
    ccallmad = df['CCALL'] - median
    mad10 = sum(i > 10 * mad for i in ccallmad)
    mad9 = sum(i > 9 * mad for i in ccallmad)
    mad8 = sum(i > 8 * mad for i in ccallmad)
    mad7 = sum(i > 7 * mad for i in ccallmad)
    mad6 = sum(i > 6 * mad for i in ccallmad)
    mad5 = sum(i > 5 * mad for i in ccallmad)
    print("For a resolution cutoff of "+str(resolution)+" with "+str(sitessearched)+" sites:")
    print("number of CCall with CCall - median > 10 * MAD = "+str(mad10))
    print("number of CCall with CCall - median >  9 * MAD = "+str(mad9))
    print("number of CCall with CCall - median >  8 * MAD = "+str(mad8))
    print("number of CCall with CCall - median >  7 * MAD = "+str(mad7))
    print("number of CCall with CCall - median >  6 * MAD = "+str(mad6))
    print("number of CCall with CCall - median >  5 * MAD = "+str(mad5))
    print("Three largest CCall values: "+str(ccallmax))
    print("")
    allmad = open(projname+"_results/mad.csv", 'a') 
    allmad.write(str(int(resolution) / 10)+","+str(sitessearched)+","+str(mad5)+","+str(mad6)+","+str(mad7)+","+str(mad8)+","+str(mad9)+","+str(mad10)+"\n")
    allmad.close()
    
################ PROCESSING ################

#run processing on either cluster or local
if pro_or_ana == 'p': 
    if not os.path.exists(projname):
        os.system("mkdir "+projname)
    i = highres
    while not (i >= lowres):
        os.system("mkdir "+projname+"/"+str(i))
        i2 = (i/10)
        j = highsites
        while not (j <= (lowsites -1)):
            os.system("mkdir "+projname+"/"+str(i)+"/"+str(j))
            os.system("cp "+insin+" ./"+projname+"/"+str(i)+"/"+str(j))
            os.system("cp "+hklin+" ./"+projname+"/"+str(i)+"/"+str(j))
            os.system("cp shelxd_job.sh "+" ./"+projname+"/"+str(i)+"/"+str(j))
            workpath = os.path.join(path, projname+"/"+str(i)+"/"+str(j))
            f = os.path.join(path, projname+"/"+str(i)+"/"+str(j)+"/"+projname+"_fa.ins")
            replace(f, "FIND", "FIND "+str(j)+"\n")
            replace(f, "SHEL", "SHEL 999 "+str(i2)+"\n")
            replace(f, "NTRY", "NTRY "+str(ntry)+"\n")
            if clust == 'l':
                print("""
                Running on local machine, this may take some time...
                      """)
                os.system("cd "+workpath+"; ./shelxd_job.sh")
            elif clust == 'c':
                print("""
                Submitting to the cluster, please run 'watch qstat' in another terminal to check on progress
                      """)
                os.system("cd "+workpath+"; qsub -P i23 -q low.q -l h_vmem=4G -N sagasu_"+str(i)+"_"+str(j)+" -pe smp 40-10 -cwd ./shelxd_job.sh")
            else:
                print("error in input...")
            j = j - 1
        i = i + 1
                
    
    print("""
          
    Done. If nothing happened, make sure you pressed l or c at the cluster question.
    
    Now preparing the files for analysis. If you ran a lot of trys, this may take some time...      
          """)

################ ANALYSIS ################
if pro_or_ana == 'p': 
    if clust == 'c':
        print("""
              
    !!!IMPORTANT!!! -  Please wait until ALL submitted cluster jobs have FINISHED before answering the following question.
        
    You can check by running 'qstat' in a new terminal.
        
        """)
        cont = (str(input("Have ALL cluster jobs FINISHED? (y/n): ")))
        cont = cont.lower()

#prep files from shelxd runs
if not os.path.exists(projname+"_results"):
    os.system("mkdir "+projname+"_results")
i = highres
while not (i >= lowres):
    i2 = (i/10)
    j = highsites
    while not (j <= (lowsites - 1)):
        lstfile = os.path.join(path, projname+"/"+str(i)+"/"+str(j)+"/"+projname+"_fa.lst")
        results(lstfile)
        j = j - 1
    i = i + 1 

#run cluster outlier analysis with optional cluster analysis
if not os.path.exists(projname+"_figures"):
    os.system("mkdir "+projname+"_figures")
i = highres
while not (i >= lowres):
    i2 = (i/10)
    j = highsites
    while not (j <= (lowsites - 1)):
        csvfile = os.path.join(path, projname+"_results/"+str(i)+"_"+str(j)+".csv")
        numbers = str(i)+"_"+str(j)
        if clusteranalysis == 'y':
            analysis(csvfile, numbers)
        else:
            print("No cluster analysis requested")
        outliers(csvfile, i, j)
        j = j - 1
    i = i + 1
    
df = pd.read_csv(projname+"_results/mad.csv", sep=',', names=['res', 'sites', 'mad5', 'mad6', 'mad7', 'mad8', 'mad9', 'mad10'])
df['score'] = (df['mad5'] * 1) + (df['mad6'] * 4) + (df['mad7'] * 8) + (df['mad8'] * 32) + (df['mad9'] * 128) + (df['mad10'] * 512)
df.sort_values(by=['score'], ascending=False,inplace=True)
top = df[['res', 'sites', 'score']]
top = df.head(10)
print("""
Here are the top 10 hits:

""")
print(top)
ax = plt.axes(projection='3d')
ax.plot_trisurf(df['res'], df['sites'], df['score'], cmap='viridis', edgecolor='none')
madplot = plt.gcf()
madplot.savefig(projname+"_figures/mad.png", dpi=600)